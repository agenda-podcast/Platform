#!/usr/bin/env python3
from __future__ import annotations

import csv
import sys
from pathlib import Path
from typing import Dict, List, Set

# Ensure repo root is on sys.path so local "platform" package wins over stdlib "platform" module.
_REPO_ROOT = Path(__file__).resolve().parents[1]
if str(_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_REPO_ROOT))
if "platform" in sys.modules and not hasattr(sys.modules["platform"], "__path__"):
    del sys.modules["platform"]

from platform.config.load_platform_config import load_platform_config


def _read_csv(path: Path) -> List[Dict[str, str]]:
    with path.open('r', encoding='utf-8', newline='') as f:
        r = csv.DictReader(f)
        if r.fieldnames is None:
            raise SystemExit(f"[VERIFY_PLATFORM][FAIL] CSV missing header: {path}")
        out: List[Dict[str, str]] = []
        for row in r:
            out.append({k: (v or '') for k, v in row.items()})
        return out


def _require_cols(path: Path, rows: List[Dict[str, str]], required: List[str]) -> None:
    if not rows:
        # Empty tables are allowed; header is already validated by DictReader.
        return
    missing = [c for c in required if c not in rows[0]]
    if missing:
        raise SystemExit(f"[VERIFY_PLATFORM][FAIL] {path} missing required columns: {missing}")


def _require_unique(path: Path, rows: List[Dict[str, str]], key: str) -> None:
    seen: Set[str] = set()
    dups: List[str] = []
    for row in rows:
        v = str(row.get(key, '') or '').strip()
        if not v:
            continue
        if v in seen:
            dups.append(v)
        else:
            seen.add(v)
    if dups:
        dups_sorted = sorted(set(dups))
        raise SystemExit(f"[VERIFY_PLATFORM][FAIL] {path} has duplicate {key}: {dups_sorted}")


def main() -> int:
    repo_root = _REPO_ROOT

    # 1) Platform config must load (strict validation is enforced by loader).
    _ = load_platform_config(repo_root)
    print('[VERIFY_PLATFORM][OK] platform_config.yml loads')

    # 2) Required maintenance-state indexes must exist and be minimally well-formed.
    ms = repo_root / 'maintenance-state'
    modules_idx = ms / 'modules_index.csv'
    workorders_idx = ms / 'workorders_index.csv'

    if not modules_idx.exists():
        raise SystemExit(f"[VERIFY_PLATFORM][FAIL] Missing {modules_idx} (run Maintenance)")
    if not workorders_idx.exists():
        raise SystemExit(f"[VERIFY_PLATFORM][FAIL] Missing {workorders_idx} (run Maintenance)")

    m_rows = _read_csv(modules_idx)
    _require_cols(modules_idx, m_rows, ['module_id', 'path'])
    _require_unique(modules_idx, m_rows, 'module_id')
    print(f"[VERIFY_PLATFORM][OK] modules_index.csv rows={len(m_rows)}")

    w_rows = _read_csv(workorders_idx)
    _require_cols(workorders_idx, w_rows, ['tenant_id', 'work_order_id', 'path', 'enabled'])
    _require_unique(workorders_idx, w_rows, 'work_order_id')
    print(f"[VERIFY_PLATFORM][OK] workorders_index.csv rows={len(w_rows)}")

    # 3) Ensure Verify workflow templates have the required markers exactly once.
    vm = repo_root / '.github' / 'workflows' / 'verify_modules.yml'
    vw = repo_root / '.github' / 'workflows' / 'verify_workorders.yml'
    for wf, marker in [
        (vm, 'AUTOGENERATED:MODULE_OPTIONS'),
        (vw, 'AUTOGENERATED:PLATFORM_WORKORDERS'),
    ]:
        txt = wf.read_text(encoding='utf-8')
        if txt.count(marker) != 2:
            raise SystemExit(f"[VERIFY_PLATFORM][FAIL] {wf} must include marker '{marker}' exactly once (BEGIN/END)")
    print('[VERIFY_PLATFORM][OK] Verify workflow markers present')

    return 0


if __name__ == '__main__':
    raise SystemExit(main())
